{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evan Racah\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from util.helper_fxns import center, scale\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ibd_pairs(path, train_frac=0.5, valid_frac=0.25, tot_num_pairs=-1):\n",
    "    '''Load up the hdf5 file given into a set of numpy arrays suitable for\n",
    "    convnets.\n",
    "\n",
    "    The output is a tuple of (train, valid, test). Each set has shape\n",
    "    (n_pairs, nchannels, xsize, ysize) where\n",
    "        (nchannels, xsize, ysize) = (4, 8, 24).\n",
    "\n",
    "    The relative size of each set can be specified in the arguments.'''\n",
    "    h5file = h5py.File(path, 'r')\n",
    "    h5set = h5file['ibd_pair_data']\n",
    "    \n",
    "    if tot_num_pairs == -1:\n",
    "        npairs = h5set.shape[0]\n",
    "    else:\n",
    "        npairs = tot_num_pairs\n",
    "    ntrain = int(train_frac * npairs)\n",
    "    nvalid = int(valid_frac * npairs)\n",
    "    ntest = npairs - ntrain - nvalid\n",
    "\n",
    "    train = np.asarray(h5set[:ntrain])\n",
    "    valid = np.asarray(h5set[ntrain:(ntrain + nvalid)])\n",
    "    test = np.asarray(h5set[(ntrain + nvalid):])\n",
    "\n",
    "    imageshape = (4, 8, 24)\n",
    "    nfeatures = reduce(mul, imageshape)\n",
    "    # Don't use all of the array since it contains the metadata as well as the\n",
    "    # pixels\n",
    "    train = train[:, :nfeatures].reshape(ntrain, *imageshape)\n",
    "    valid = valid[:, :nfeatures].reshape(nvalid, *imageshape)\n",
    "    test = test[:, :nfeatures].reshape(ntest, *imageshape)\n",
    "\n",
    "    return (train, valid, test)\n",
    "\n",
    "\n",
    "def get_ibd_data(path_prefix=\"/global/homes/s/skohn/ml/dayabay-data-conversion/extract_ibd\", mode='standardize',\n",
    "                tot_num_pairs=-1):\n",
    "    \n",
    "    h5files = []\n",
    "\n",
    "    name = os.path.join(path_prefix,\"ibd_yasu_%d_%d.h5\")\n",
    "    h5file = name % (i*10000, (i+1)*10000-1)\n",
    "    train, test, val = load_ibd_pairs(h5file, tot_num_pairs=tot_num_pairs)\n",
    "\n",
    "    center(train)\n",
    "    center(val)\n",
    "    center(test)\n",
    "    scale(train, 1, mode=mode)\n",
    "    scale(val, 1, mode=mode)\n",
    "    scale(test, 1, mode=mode)\n",
    "    \n",
    "    return train, val, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
