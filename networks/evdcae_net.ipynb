{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from print_n_plot.ipynb\n",
      "importing Jupyter notebook from train_val.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import theano\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import lasagne\n",
    "from lasagne import layers as L\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#temporary!\n",
    "if __name__ == \"__main__\":\n",
    "    #just a little trick for testing in order to get the data loader\n",
    "    sys.path.insert(0,os.path.dirname(os.getcwd()))\n",
    "    \n",
    "\n",
    "from util.data_loaders import get_ibd_data\n",
    "from networks.Network import AbstractNetwork\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from train_val import train\n",
    "from networks.preprocessing import scale, scale_min_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DenoisingConvAe(AbstractNetwork):\n",
    "    def __init__(self, network_kwargs, save_dir='./results', load_path=None):\n",
    "        self.network_kwargs = network_kwargs\n",
    "        self.save_dir = save_dir\n",
    "        \n",
    "        self.train_fn, \\\n",
    "        self.val_fn, \\\n",
    "        self.pred_fn, \\\n",
    "        self.hlayer_fn,\\\n",
    "        self.salmap_fn,\\\n",
    "        self.network = build_network(**self.network_kwargs)\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self, x_train, y_train, x_val,y_val):\n",
    "        \n",
    "        x_train, x_val = self.preprocess_data(x_train, x_val)\n",
    "        train((x_train, x_train, x_val,x_val),\n",
    "                             self.network, \n",
    "                             self.train_fn, \n",
    "                             self.val_fn,\n",
    "                             hlayer_fn = self.hlayer_fn,\n",
    "                             pred_fn = self.pred_fn,\n",
    "                             salmap_fn = self.salmap_fn,\n",
    "                             epochs=self.network_kwargs['epochs'],\n",
    "                             batchsize=self.network_kwargs['batch_size'],\n",
    "                             save_path = self.save_dir)\n",
    "        \n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.pred_fn(x)\n",
    "        \n",
    "\n",
    "    def extract_hidden_layer(self, data):\n",
    "        return self.hlayer_fn(data)\n",
    "    \n",
    "    def get_saliency_map(self,data):\n",
    "        return self.salmap_fn(data)\n",
    "        \n",
    "\n",
    "    def minibatch_iterator(self, x, y):\n",
    "        '''iterate over minibatches'''\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def preprocess_data(self, train,val ):\n",
    "        mins, maxes = scale_min_max(train)\n",
    "        scale_min_max(val,mins=mins,maxes=maxes)\n",
    "        return train, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(learning_rate = 0.01,\n",
    "                  input_shape=(None,2,8,24),\n",
    "                  momentum = 0.9,\n",
    "                  num_filters=128,\n",
    "                  num_fc_units=1024,\n",
    "                  num_extra_conv=0, \n",
    "                  num_pool=4,\n",
    "                  nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                  w_init=lasagne.init.HeNormal(),\n",
    "                  dropout_p=0.,\n",
    "                  corruption_p = 0.3,\n",
    "                  load=False,\n",
    "                 **unused_kwargs):\n",
    "    \n",
    "    input_var = T.tensor4('input_var')\n",
    "    target_var = T.tensor4('target_var')\n",
    "    print(\"Building model and compiling functions...\")\n",
    "    \n",
    "    \n",
    "    network, hid_layer = build_denoising_convae(input_var,\n",
    "                                                input_shape,\n",
    "                                                num_filters,\n",
    "                                                num_fc_units,\n",
    "                                                num_extra_conv, \n",
    "                                                num_pool,\n",
    "                                                nonlinearity,\n",
    "                                                w_init,\n",
    "                                                dropout_p,\n",
    "                                                corruption_p)\n",
    "    \n",
    "    if load:\n",
    "        with np.load('model.npz') as f:\n",
    "            param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "            lasagne.layers.set_all_param_values(network, param_values)\n",
    "\n",
    "\n",
    "    prediction = lasagne.layers.get_output(network, deterministic=False)\n",
    "    hid_layer_output = lasagne.layers.get_output(hid_layer, deterministic=True)\n",
    "    loss = lasagne.objectives.squared_error(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    \n",
    "  \n",
    "\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.squared_error(test_prediction,\n",
    "                                                                target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "\n",
    "\n",
    "    salmap = theano.grad(hid_layer_output.sum(), wrt=input_var)\n",
    "\n",
    "    test_acc = test_loss \n",
    "\n",
    "\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "\n",
    "\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    \n",
    "    pred_fn = theano.function([input_var], test_prediction)\n",
    "    \n",
    "    hlayer_fn = theano.function([input_var], hid_layer_output )\n",
    "    \n",
    "    salmap_fn = theano.function([input_var], salmap)\n",
    "\n",
    "    return train_fn, val_fn, pred_fn, hlayer_fn, salmap_fn, network\n",
    "\n",
    "def build_denoising_convae(input_var,input_shape,\n",
    "                                  num_filters,\n",
    "                                  num_fc_units,\n",
    "                                  num_extra_conv, \n",
    "                                  num_pool,\n",
    "                                  nonlinearity,\n",
    "                                  w_init,\n",
    "                                  dropout_p,\n",
    "                                  corruption_p):\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    rng = np.random.RandomState(498)\n",
    "    theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "    #do denoising here\n",
    "    corrup_input = theano_rng.binomial(size=input_var.shape, n=1,\n",
    "                                        p=1 - corruption_p,\n",
    "                                        dtype=theano.config.floatX) * input_var\n",
    "    \n",
    "    \n",
    "    \n",
    "    #input var is (n_ex x 2 x 8 x 24)\n",
    "    network = L.InputLayer(shape=input_shape, input_var=corrup_input)\n",
    "    print network.get_output_shape_for(input_shape)\n",
    "    #output of this is num_filters x 11 x 12\n",
    "    network = L.Conv2DLayer(network, \n",
    "                            num_filters=num_filters, \n",
    "                            filter_size=(2,2),\n",
    "                            pad=(2,0),\n",
    "                            stride=(1,2),\n",
    "                            nonlinearity=nonlinearity,\n",
    "                            W=w_init)\n",
    "    print network.get_output_shape_for(network.input_shape)\n",
    "    \n",
    "    #output of this is num_filters x 6 x 6\n",
    "    network = L.Conv2DLayer(network, num_filters=num_filters, \n",
    "                                 filter_size=(2,2),\n",
    "                                 pad=(1,0),\n",
    "                                 stride=2)\n",
    "    \n",
    "    last_conv_shape = network.get_output_shape_for(network.input_shape)\n",
    "    print last_conv_shape\n",
    "    \n",
    "    #output of this is num_fc_units\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "                                lasagne.layers.dropout(network, p=dropout_p),\n",
    "                                num_units=num_fc_units,\n",
    "                                nonlinearity=nonlinearity)\n",
    "    print network.get_output_shape_for(network.input_shape)\n",
    "    #capture hidden layer\n",
    "    hid_layer = network\n",
    "    \n",
    "    #output of this is num_filters*6*6\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "                                lasagne.layers.dropout(network, p=dropout_p),\n",
    "                                num_units=np.prod(last_conv_shape[1:]),\n",
    "                                nonlinearity=nonlinearity)\n",
    "    print network.get_output_shape_for(network.input_shape)\n",
    "    \n",
    "    #output of this is num_filters x 6 x 6\n",
    "    network = lasagne.layers.ReshapeLayer(network, shape=([0],last_conv_shape[1],last_conv_shape[2],last_conv_shape[3]))\n",
    "    \n",
    "    print network.get_output_shape_for(network.input_shape)\n",
    "    #output of this is num_filters x 11 x 12\n",
    "    network = lasagne.layers.TransposedConv2DLayer(network, num_filters=num_filters, \n",
    "                                 filter_size=(3,2),\n",
    "                                 crop=(1,0),\n",
    "                                 stride=(2,2),\n",
    "                                 nonlinearity=nonlinearity,\n",
    "                                 W=w_init)\n",
    "    \n",
    "    print network.get_output_shape_for(network.input_shape)\n",
    "    #output of this is num_filters x 8  x 24\n",
    "    #note the number of filters has to be same as number of input channels\n",
    "    network = lasagne.layers.TransposedConv2DLayer(network, num_filters=input_shape[1], \n",
    "                                 filter_size=(2,2),\n",
    "                                 crop=(2,0),\n",
    "                                 stride=(1,2),\n",
    "                                 nonlinearity=lasagne.nonlinearities.linear,\n",
    "                                 W=w_init)\n",
    "    print network.get_output_shape_for(network.input_shape)\n",
    "\n",
    "    \n",
    "    return network, hid_layer\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #make data\n",
    "    xtr,xv,xte = get_ibd_data(tot_num_pairs=30, preprocess=True)\n",
    "    train_fn, val_fn, pred_fn, hlayer_fn, salmap_fn, network = build_network(input_shape=(None,4,8,24))\n",
    "    a=train_fn(xtr,xtr)\n",
    "    b=pred_fn(xtr)\n",
    "    c=hlayer_fn(xtr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from matplotlib import pyplot as plt\n",
    "    %matplotlib inline\n",
    "    plt.imshow(b[0,0],interpolation='none')\n",
    "    plt.colorbar()\n",
    "    plt.figure(2)\n",
    "    plt.imshow(xtr[0,0],interpolation='none')\n",
    "    plt.colorbar()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    xtr,xv,xte = get_ibd_data(tot_num_pairs=30, preprocess=True)\n",
    "    for x in [xtr,xv,xte]:\n",
    "        assert(x.min() > -1.1)\n",
    "        assert (x.max() < 1.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x_train, x_val, x_test = get_ibd_data(tot_num_pairs=200, preprocess=True, just_charges=True)\n",
    "\n",
    "    dca = DenoisingConvAe(network_kwargs={'learning_rate':0.01}, \n",
    "                          train_kwargs={'num_epochs': 11, 'save_path': os.path.dirname(os.getcwd()) + '/results'})\n",
    "\n",
    "    dca.fit(x_train,x_train,x_val,x_val)\n",
    "\n",
    "    rec= dca.predict(x_train)\n",
    "\n",
    "    hlayer = dca.extract_hidden_layer(x_train)\n",
    "\n",
    "#     salmap =\n",
    "\n",
    "    ts = TSNE(perplexity=50).fit_transform(hlayer)\n",
    "\n",
    "    plt.scatter(ts[:,0], ts[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
