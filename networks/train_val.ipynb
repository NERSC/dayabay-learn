{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from print_n_plot.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import time\n",
    "from nbfinder import NotebookFinder\n",
    "\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from print_n_plot import print_train_results,plot_learn_curve,print_val_results, plot_reconstruction, calc_plot_n_save_tsne\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: adding logging\n",
    "#TODO add special way of saving run info based on run number or date or something\n",
    "#TODO add getting weights over updates\n",
    "def train(datasets,network,train_fn, val_fn,hlayer_fn=None,pred_fn=None,salmap_fn=None, num_epochs=50, save_weights=False, save_plots=True, save_path='./results',\n",
    "          batchsize=128, network_kwargs={}, load_path=None):\n",
    "    \n",
    "    \"\"\"Train function\n",
    "\n",
    "    Arguments:\n",
    "        datasets (sequence): tuple or list of x_tr, y_tr, x_val, y_val, x_te, y_te\n",
    "        num_epochs (int): number of epochs\n",
    "\n",
    "    Returns:\n",
    "        lasagne layers instance: The last layer of the network with trained weights\n",
    "\n",
    "    .. _PEP 484:\n",
    "        https://www.python.org/dev/peps/pep-0484/\n",
    "\n",
    "    \"\"\"\n",
    "    #todo add in detect\n",
    "    x_tr, y_tr, x_val, y_val= datasets\n",
    "    \n",
    "\n",
    "    if batchsize is None or x_tr.shape[0] < batchsize:\n",
    "        batchsize = x_tr.shape[0]\n",
    "\n",
    "    print \"Starting training...\" \n",
    "    \n",
    "\n",
    "    train_errs, train_accs, val_errs, val_accs = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        do_one_epoch(epoch,num_epochs, x_tr, y_tr, x_val, y_val,\n",
    "                     batchsize, train_fn, val_fn, \n",
    "                     train_errs, train_accs, val_errs, val_accs)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            plot_learn_curve(train_errs,val_errs, 'err', save_plots=save_plots,path=save_path)\n",
    "            plot_learn_curve(train_accs,val_accs, 'acc', save_plots=save_plots, path=save_path)\n",
    "            if hlayer_fn:\n",
    "                hlayer = hlayer_fn(x_tr)\n",
    "                calc_plot_n_save_tsne(x_train=x_tr, hlayer=hlayer, run_dir=save_path)\n",
    "            if pred_fn:\n",
    "                rec = pred_fn(x_tr)\n",
    "                n_ims = rec.shape[0]\n",
    "                \n",
    "                plot_reconstruction(x_tr[:,0], rec[:,0], indx=0,save=save_plots, path=save_path)\n",
    "                plot_reconstruction(x_tr[:,0], rec[:,0], indx=25,save=save_plots,  path=save_path)\n",
    "                plot_reconstruction(x_tr[:,0], rec[:,0], indx=50,save=save_plots,  path=save_path)\n",
    "                plot_reconstruction(x_tr[:,0], rec[:,0], indx=n_ims-1,save=save_plots,  path=save_path)\n",
    "            if salmap_fn:\n",
    "                sal = salmap_fn(x_tr)\n",
    "                plt.figure(47)\n",
    "                plt.imshow(x_tr[0,0], interpolation='none')\n",
    "                plt.savefig(save_path + '/orig_nosal.png' )\n",
    "                plt.show()\n",
    "                plt.figure(48)\n",
    "                plt.imshow(np.abs(sal[0,0]),interpolation='none', cmap='gray')\n",
    "                plt.savefig(save_path + '/sal.png')\n",
    "                plt.show()\n",
    "                \n",
    "                \n",
    "            #plot weights or updates or something \n",
    "            \n",
    "            \n",
    "        if save_weights and epoch % 10 == 0:\n",
    "        # Optionally, you could now dump the network weights to a file like this:\n",
    "            np.savez('%s.npz'%(mode), *lasagne.layers.get_all_param_values(network))\n",
    "    return network\n",
    "        #(train_errs[-1], train_accs[-1], val_errs[-1], val_accs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0,len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx: start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "def train_one_epoch(x,y,batchsize, train_fn, val_fn):\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(x, y, batchsize, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        _, acc = val_fn(inputs, targets)\n",
    "        train_acc += acc\n",
    "        train_batches += 1\n",
    "    return train_err, train_acc, train_batches\n",
    "\n",
    "def val_one_epoch(x,y,batchsize, val_fn):\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(x,y, batchsize, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "        return val_err, val_acc, val_batches\n",
    "def do_one_epoch(epoch,num_epochs, x_train,y_train, x_val, y_val, batchsize, train_fn, val_fn,\n",
    "                 train_errs, train_accs, val_errs, val_accs):\n",
    "        start_time = time.time()\n",
    "        tr_err, tr_acc, tr_batches = train_one_epoch(x_train, y_train,\n",
    "                                                     batchsize=batchsize,\n",
    "                                                     train_fn=train_fn,\n",
    "                                                     val_fn=val_fn)\n",
    "                \n",
    "        train_errs.append(tr_err / tr_batches)\n",
    "        train_accs.append(tr_acc / tr_batches)\n",
    "        print_train_results(epoch, num_epochs, start_time, tr_err / tr_batches, tr_acc / tr_batches)\n",
    "        \n",
    "\n",
    "        val_err, val_acc, val_batches = val_one_epoch(x_val, y_val,\n",
    "                                                     batchsize=y_val.shape[0],\n",
    "                                                      val_fn=val_fn)\n",
    "        val_errs.append(val_err / val_batches)\n",
    "        val_accs.append(val_acc / val_batches)\n",
    "        print_val_results(val_err, val_acc / val_batches)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
