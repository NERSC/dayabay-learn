{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from print_n_plot.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import time\n",
    "from nbfinder import NotebookFinder\n",
    "\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from print_n_plot import print_train_results,plot_learn_curve,print_val_results, plot_side_by_side, calc_plot_n_save_tsne\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-5372f2d6b1eb>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-5372f2d6b1eb>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    plot_side_by_side(x_inps,rec,inds,epoch,mode='rec', save=True, path=save_path, cmap=None):\u001b[0m\n\u001b[0m                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#TODO: adding logging\n",
    "#TODO add special way of saving run info based on run number or date or something\n",
    "#TODO add getting weights over updates\n",
    "def train(datasets,\n",
    "          network,\n",
    "          train_fn, val_fn, hlayer_fn=None,pred_fn=None,salmap_fn=None,\n",
    "          epochs=50, \n",
    "          save_weights=True, \n",
    "          save_plots=True,\n",
    "          save_path='./results',\n",
    "          batchsize=128,\n",
    "          load_path=None):\n",
    "\n",
    "    \n",
    "    logger = setup_logging(save_path)\n",
    "    #todo add in detect\n",
    "    x_tr, y_tr, x_val, y_val= datasets\n",
    "    \n",
    "\n",
    "    inds = np.random.randint(0,x_tr.shape[0], size=(4,))\n",
    "    \n",
    "    if batchsize is None or x_tr.shape[0] < batchsize:\n",
    "        batchsize = x_tr.shape[0]\n",
    "\n",
    "    print \"Starting training...\" \n",
    "    \n",
    "\n",
    "    train_errs, train_accs, val_errs, val_accs, val_counter = [], [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        do_one_epoch(epoch,epochs, x_tr, y_tr, x_val, y_val,\n",
    "                     batchsize, train_fn, val_fn, \n",
    "                     train_errs, train_accs, val_errs, val_accs, val_counter,logger)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            \n",
    "            plot_learn_curve(train_errs,val_errs,val_counter, 'err', save_plots=save_plots,path=save_path)\n",
    "            plot_learn_curve(train_accs,val_accs,val_counter, 'acc', save_plots=save_plots, path=save_path)\n",
    "            if hlayer_fn:\n",
    "                hlayer = hlayer_fn(x_tr)\n",
    "                calc_plot_n_save_tsne(x_train=x_tr, hlayer=hlayer, run_dir=save_path)\n",
    "            if pred_fn:\n",
    "                rec = pred_fn(x_tr)\n",
    "                n_ims = rec.shape[0]\n",
    "                plot_side_by_side(x_tr,rec,inds,epoch,mode='rec', save=True, path=save_path, cmap=None)\n",
    "            if salmap_fn:\n",
    "                sal = np.abs(salmap_fn(x_tr))\n",
    "                plot_side_by_side(x_tr,sal,inds,epoch,mode='sal', save=True, path=save_path, cmap='gray')\n",
    "            \n",
    "                \n",
    "                \n",
    "            #plot weights or updates or something \n",
    "            \n",
    "            \n",
    "        if save_weights and epoch % 10 == 0:\n",
    "        # Optionally, you could now dump the network weights to a file like this:\n",
    "            np.savez('%s/%s.npz'%(save_path,epoch), *lasagne.layers.get_all_param_values(network))\n",
    "    return network\n",
    "        #(train_errs[-1], train_accs[-1], val_errs[-1], val_accs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    if batchsize > inputs.shape[0]:\n",
    "        batchsize=inputs.shape[0]\n",
    "    for start_idx in range(0,len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx: start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "def train_one_epoch(x,y,batchsize, train_fn, val_fn):\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(x, y, batchsize, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        _, acc = val_fn(inputs, targets)\n",
    "        train_acc += acc\n",
    "        train_batches += 1\n",
    "    return train_err, train_acc, train_batches\n",
    "\n",
    "def val_one_epoch(x, y, batchsize, val_fn):\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(x,y, batchsize, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "        return val_err, val_acc, val_batches\n",
    "def do_one_epoch(epoch,epochs, x_train, y_train, x_val, y_val, batchsize, train_fn, val_fn,\n",
    "                 train_errs, train_accs, val_errs, val_accs, val_counter, logger):\n",
    "        start_time = time.time()\n",
    "        tr_err, tr_acc, tr_batches = train_one_epoch(x_train, y_train,\n",
    "                                                     batchsize=batchsize,\n",
    "                                                     train_fn=train_fn,\n",
    "                                                     val_fn=val_fn)\n",
    "                \n",
    "        train_errs.append(tr_err / tr_batches)\n",
    "        train_accs.append(tr_acc / tr_batches)\n",
    "        print_train_results(epoch, epochs, start_time, tr_err / tr_batches, tr_acc / tr_batches, logger)\n",
    "        \n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            val_err, val_acc, val_batches = val_one_epoch(x_val, y_val,\n",
    "                                                         batchsize=batchsize,\n",
    "                                                          val_fn=val_fn)\n",
    "\n",
    "            val_counter.append(epoch)\n",
    "            val_errs.append(val_err / val_batches)\n",
    "            val_accs.append(val_acc / val_batches)\n",
    "            print_val_results(val_err, val_acc / val_batches, logger)\n",
    "        \n",
    "\n",
    "def setup_logging(save_path):\n",
    "    logger = logging.getLogger('simple_example')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler('%s/training.log'%(save_path))\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    # create console handler with a higher log level\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "    return logger\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
